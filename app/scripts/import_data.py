
import sys
import os
from pathlib import Path
from decimal import Decimal, ROUND_HALF_UP
from typing import Any, Optional, Union

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å Python
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
sys.path.insert(0, str(project_root))

# –¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
from app.database import (
    engine, get_session, create_all_tables,
    MaterialType, ProductType, Workshop, Product, product_workshop_table
)
from app.config import EXCEL_FILES

import pandas as pd
from sqlalchemy import select
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('import.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class DataTypeValidator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def validate_string(value: Any, field_name: str, max_length: Optional[int] = None) -> str:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        if pd.isna(value) or value is None:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        result = str(value).strip()
        
        if not result:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π")
        
        if max_length and len(result) > max_length:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}' —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤ "
                f"(–º–∞–∫—Å–∏–º—É–º {max_length})"
            )
        
        return result
    
    @staticmethod
    def validate_integer(value: Any, field_name: str, min_value: Optional[int] = None, 
                         max_value: Optional[int] = None) -> int:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª"""
        if pd.isna(value) or value is None:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
        if isinstance(value, str):
            value = value.replace(' ', '').replace(',', '').strip()
        
        try:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ int
            if isinstance(value, float) and value.is_integer():
                result = int(value)
            else:
                result = int(float(value))
        except (ValueError, TypeError) as e:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ"
            ) from e
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        if min_value is not None and result < min_value:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –∑–Ω–∞—á–µ–Ω–∏–µ {result} –º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ {min_value}"
            )
        
        if max_value is not None and result > max_value:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –∑–Ω–∞—á–µ–Ω–∏–µ {result} –±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ {max_value}"
            )
        
        return result
    
    @staticmethod
    def validate_float(value: Any, field_name: str, min_value: Optional[float] = None,
                      max_value: Optional[float] = None, precision: int = 2) -> float:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —á–∏—Å–µ–ª —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π"""
        if pd.isna(value) or value is None:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
        if isinstance(value, str):
            value = value.replace(' ', '').replace(',', '').strip()
        
        try:
            result = float(value)
        except (ValueError, TypeError) as e:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{value}' –≤ —á–∏—Å–ª–æ"
            ) from e
        
        # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
        if precision:
            result = float(Decimal(str(result)).quantize(
                Decimal(f"1.{'0' * precision}"), rounding=ROUND_HALF_UP
            ))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        if min_value is not None and result < min_value:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –∑–Ω–∞—á–µ–Ω–∏–µ {result:.{precision}f} "
                f"–º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ {min_value}"
            )
        
        if max_value is not None and result > max_value:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –∑–Ω–∞—á–µ–Ω–∏–µ {result:.{precision}f} "
                f"–±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ {max_value}"
            )
        
        return result

    @staticmethod
    def validate_percentage(value: Any, field_name: str) -> float:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π - —Ö—Ä–∞–Ω–∏–º –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç—ã (0.8 –¥–ª—è 0.8%)"""
        if pd.isna(value) or value is None:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        original_value = str(value)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        if isinstance(value, str):
            value = value.replace('%', '').strip()
            value = value.replace(',', '.')
        elif isinstance(value, float):
            # –ï—Å–ª–∏ pandas —É–∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–ª 0,80% –≤ 0.008 (–¥–æ–ª–∏)
            if value < 0.01:  # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ–Ω—å—à–µ 1% (–≤ –¥–æ–ª—è—Ö)
                value = value * 100  # 0.008 ‚Üí 0.8
        
        try:
            result = float(value)
        except (ValueError, TypeError) as e:
            raise ValueError(
                f"–ü–æ–ª–µ '{field_name}': –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å '{original_value}' –≤ —á–∏—Å–ª–æ"
            ) from e
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 0-100 (–∞ –Ω–µ 0-1)
        if result < 0:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}': –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º")
        if result > 100:  # 100% –º–∞–∫—Å–∏–º—É–º (–∞ –Ω–µ 1!)
            raise ValueError(f"–ü–æ–ª–µ '{field_name}': –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å 100%")
        
        # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 4 –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
        return float(Decimal(str(result)).quantize(Decimal('0.0001'), rounding=ROUND_HALF_UP))
    
    @staticmethod
    def validate_positive_float(value: Any, field_name: str, precision: int = 2) -> float:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª"""
        result = DataTypeValidator.validate_float(value, field_name, precision=precision)
        
        if result < 0:
            raise ValueError(f"–ü–æ–ª–µ '{field_name}' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º")
        
        return result
    
    @staticmethod
    def validate_positive_integer(value: Any, field_name: str) -> int:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª"""
        result = DataTypeValidator.validate_integer(value, field_name, min_value=1)
        return result

def clean_number(value: Any) -> float:
    """–û—á–∏—Å—Ç–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    try:
        return DataTypeValidator.validate_float(value, "—á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", precision=2)
    except ValueError as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —á–∏—Å–ª–∞: {e}")
        return 0.0

# def clean_percentage(value: Any) -> float:
#     """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
#     try:
#         return DataTypeValidator.validate_percentage(value, "–ø—Ä–æ—Ü–µ–Ω—Ç")
#     except ValueError as e:
#         logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–∞: {e}")
#         return 0.0

def clean_percentage(value: Any) -> float:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    try:
        return DataTypeValidator.validate_percentage(value, "–ø—Ä–æ—Ü–µ–Ω—Ç")
    except ValueError as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–∞: {e}")
        return 0.0

def import_material_types(session):
    """–ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    logger.info("–ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤...")
    
    file_path = EXCEL_FILES['material_types']
    if not file_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    df = pd.read_excel(file_path)
    imported_count = 0
    error_count = 0
    
    for idx, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            material_name = DataTypeValidator.validate_string(
                row['–¢–∏–ø –º–∞—Ç–µ—Ä–∏–∞–ª–∞'], '–¢–∏–ø –º–∞—Ç–µ—Ä–∏–∞–ª–∞', max_length=100
            )
            
            loss_percentage = DataTypeValidator.validate_percentage(
                row['–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å —Å—ã—Ä—å—è'], '–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å —Å—ã—Ä—å—è'
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω–∏
            existing = session.query(MaterialType).filter_by(name=material_name).first()
            if existing:
                logger.warning(f"–ú–∞—Ç–µ—Ä–∏–∞–ª '{material_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            material = MaterialType(
                name=material_name,
                loss_percentage=loss_percentage
            )
            session.add(material)
            imported_count += 1
            
            logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –º–∞—Ç–µ—Ä–∏–∞–ª: {material_name} ({loss_percentage:.4f})")
            
        except ValueError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: {e}")
        except Exception as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    session.commit()
    logger.info(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count} —Ç–∏–ø–æ–≤ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –æ—à–∏–±–æ–∫: {error_count}")

def import_product_types(session):
    """–ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    logger.info("–ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ –ø—Ä–æ–¥—É–∫—Ü–∏–∏...")
    
    file_path = EXCEL_FILES['product_types']
    if not file_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    df = pd.read_excel(file_path)
    imported_count = 0
    error_count = 0
    
    for idx, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            type_name = DataTypeValidator.validate_string(
                row['–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏'], '–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏', max_length=100
            )
            
            coefficient = DataTypeValidator.validate_positive_float(
                row['–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–∏–ø–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'], '–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–∏–ø–∞ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', precision=2
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω–∏
            existing = session.query(ProductType).filter_by(name=type_name).first()
            if existing:
                logger.warning(f"–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏ '{type_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            product_type = ProductType(
                name=type_name,
                coefficient=coefficient
            )
            session.add(product_type)
            imported_count += 1
            
            logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω —Ç–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏: {type_name} (–∫–æ—ç—Ñ—Ñ: {coefficient})")
            
        except ValueError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: {e}")
        except Exception as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    session.commit()
    logger.info(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count} —Ç–∏–ø–æ–≤ –ø—Ä–æ–¥—É–∫—Ü–∏–∏, –æ—à–∏–±–æ–∫: {error_count}")

def import_workshops(session):
    """–ò–º–ø–æ—Ä—Ç —Ü–µ—Ö–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    logger.info("–ò–º–ø–æ—Ä—Ç —Ü–µ—Ö–æ–≤...")
    
    file_path = EXCEL_FILES['workshops']
    if not file_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    df = pd.read_excel(file_path)
    
    # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
    df.columns = df.columns.str.strip()
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
    column_mapping = {
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ ': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞',
        '–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞': '–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞',
        '–¢–∏–ø —Ü–µ—Ö–∞': '–¢–∏–ø —Ü–µ—Ö–∞'
    }
    
    for old_col, new_col in column_mapping.items():
        if old_col in df.columns:
            df = df.rename(columns={old_col: new_col})
    
    imported_count = 0
    error_count = 0
    
    for idx, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            workshop_name = DataTypeValidator.validate_string(
                row['–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞'], '–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞', max_length=100
            )
            
            workshop_type = DataTypeValidator.validate_string(
                row['–¢–∏–ø —Ü–µ—Ö–∞'], '–¢–∏–ø —Ü–µ—Ö–∞', max_length=50
            )
            
            employee_count = DataTypeValidator.validate_positive_integer(
                row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞'], 
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞'
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω–∏
            existing = session.query(Workshop).filter_by(name=workshop_name).first()
            if existing:
                logger.warning(f"–¶–µ—Ö '{workshop_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            workshop = Workshop(
                name=workshop_name,
                workshop_type=workshop_type,
                employee_count=employee_count
            )
            session.add(workshop)
            imported_count += 1
            
            logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω —Ü–µ—Ö: {workshop_name} ({employee_count} —á–µ–ª.)")
            
        except ValueError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: {e}")
        except KeyError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü: {e}")
        except Exception as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    session.commit()
    logger.info(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count} —Ü–µ—Ö–æ–≤, –æ—à–∏–±–æ–∫: {error_count}")

def import_products(session):
    """–ò–º–ø–æ—Ä—Ç –ø—Ä–æ–¥—É–∫—Ü–∏–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    logger.info("–ò–º–ø–æ—Ä—Ç –ø—Ä–æ–¥—É–∫—Ü–∏–∏...")
    
    file_path = EXCEL_FILES['products']
    if not file_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ –∏–º–µ–Ω –Ω–∞ ID
    material_map = {m.name: m.id for m in session.query(MaterialType).all()}
    product_type_map = {pt.name: pt.id for pt in session.query(ProductType).all()}
    
    imported_count = 0
    error_count = 0
    skipped_count = 0
    
    for idx, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            material_name = DataTypeValidator.validate_string(
                row['–û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ç–µ—Ä–∏–∞–ª'], '–û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ç–µ—Ä–∏–∞–ª', max_length=100
            )
            
            product_type_name = DataTypeValidator.validate_string(
                row['–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏'], '–¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏', max_length=100
            )
            
            product_name = DataTypeValidator.validate_string(
                row['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'], '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', max_length=200
            )
            
            # –ê—Ä—Ç–∏–∫—É–ª - —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ
            article = DataTypeValidator.validate_integer(
                row['–ê—Ä—Ç–∏–∫—É–ª'], '–ê—Ä—Ç–∏–∫—É–ª', min_value=1
            )
            
            min_price = DataTypeValidator.validate_positive_float(
                row['–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è –ø–∞—Ä—Ç–Ω–µ—Ä–∞'],
                '–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–ª—è –ø–∞—Ä—Ç–Ω–µ—Ä–∞',
                precision=2
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤
            if material_name not in material_map:
                skipped_count += 1
                logger.warning(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ú–∞—Ç–µ—Ä–∏–∞–ª '{material_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            if product_type_name not in product_type_map:
                skipped_count += 1
                logger.warning(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –¢–∏–ø –ø—Ä–æ–¥—É–∫—Ü–∏–∏ '{product_type_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∞—Ä—Ç–∏–∫—É–ª–∞
            existing_article = session.query(Product).filter_by(article=str(article)).first()
            if existing_article:
                logger.warning(
                    f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ü—Ä–æ–¥—É–∫—Ç —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º '{article}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç "
                    f"('{existing_article.name}'), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º"
                )
                skipped_count += 1
                continue
            
            product = Product(
                article=str(article),  # –•—Ä–∞–Ω–∏–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
                name=product_name,
                product_type_id=product_type_map[product_type_name],
                material_id=material_map[material_name],
                min_partner_price=min_price
            )
            session.add(product)
            imported_count += 1
            
            logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–æ–¥—É–∫—Ç: {product_name} (–∞—Ä—Ç: {article})")
            
        except ValueError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: {e}")
        except KeyError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü: {e}")
        except Exception as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    session.commit()
    logger.info(
        f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count} –ø—Ä–æ–¥—É–∫—Ç–æ–≤, "
        f"–ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}, –æ—à–∏–±–æ–∫: {error_count}"
    )

def import_product_workshop_links(session):
    """–ò–º–ø–æ—Ä—Ç —Å–≤—è–∑–µ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∏ —Ü–µ—Ö–æ–≤ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    logger.info("–ò–º–ø–æ—Ä—Ç —Å–≤—è–∑–µ–π –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –∏ —Ü–µ—Ö–æ–≤...")
    
    file_path = EXCEL_FILES['product_workshop']
    if not file_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    df = pd.read_excel(file_path)
    df.columns = df.columns.str.strip()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞
    product_map = {p.name: p.id for p in session.query(Product).all()}
    workshop_map = {w.name: w.id for w in session.query(Workshop).all()}
    
    imported_count = 0
    error_count = 0
    skipped_count = 0
    
    for idx, row in df.iterrows():
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            product_name = DataTypeValidator.validate_string(
                row['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏'], '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ü–∏–∏', max_length=200
            )
            
            workshop_name = DataTypeValidator.validate_string(
                row['–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞'], '–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ—Ö–∞', max_length=100
            )
            
            manufacturing_time = DataTypeValidator.validate_positive_float(
                row['–í—Ä–µ–º—è –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è, —á'],
                '–í—Ä–µ–º—è –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è',
                precision=1
            )
            
            if product_name not in product_map:
                skipped_count += 1
                logger.warning(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ü—Ä–æ–¥—É–∫—Ç '{product_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            if workshop_name not in workshop_map:
                skipped_count += 1
                logger.warning(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –¶–µ—Ö '{workshop_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è —Å–≤—è–∑—å
            existing_link = session.execute(
                select(product_workshop_table)
                .where(
                    (product_workshop_table.c.product_id == product_map[product_name]) &
                    (product_workshop_table.c.workshop_id == workshop_map[workshop_name])
                )
            ).fetchone()
            
            if existing_link:
                logger.warning(
                    f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –°–≤—è–∑—å –ø—Ä–æ–¥—É–∫—Ç–∞ '{product_name}' —Å —Ü–µ—Ö–æ–º "
                    f"'{workshop_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º"
                )
                skipped_count += 1
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑—å –≤–æ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            session.execute(
                product_workshop_table.insert().values(
                    product_id=product_map[product_name],
                    workshop_id=workshop_map[workshop_name],
                    manufacturing_time_hours=manufacturing_time
                )
            )
            imported_count += 1
            
            logger.debug(
                f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å–≤—è–∑—å: '{product_name}' - '{workshop_name}' "
                f"({manufacturing_time} —á)"
            )
            
        except ValueError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: {e}")
        except KeyError as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü: {e}")
        except Exception as e:
            error_count += 1
            logger.error(f"–°—Ç—Ä–æ–∫–∞ {idx + 2}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    
    session.commit()
    logger.info(
        f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count} —Å–≤—è–∑–µ–π, "
        f"–ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}, –æ—à–∏–±–æ–∫: {error_count}"
    )

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–º–ø–æ—Ä—Ç–∞"""
    print("=" * 70)
    print("–ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–• –í –ë–ê–ó–£ –î–ê–ù–ù–´–• –° –ü–†–û–í–ï–†–ö–û–ô –¢–ò–ü–û–í")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
    create_all_tables()
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é
    with get_session() as session:
        try:
            # –ü–æ—Ä—è–¥–æ–∫ –∏–º–ø–æ—Ä—Ç–∞ –í–ê–ñ–ï–ù!
            import_material_types(session)
            import_product_types(session)
            import_workshops(session)
            import_products(session)
            import_product_workshop_links(session)
            
            print("\n" + "=" * 70)
            print("–ò–ú–ü–û–†–¢ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
            print("=" * 70)
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print_statistics(session)
            
            # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É
            print("\n" + "=" * 70)
            print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø")
            print("=" * 70)
            print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫—É –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∏–º–ø–æ—Ä—Ç–∞:")
            print("python -m app.scripts.validate_import")
            
        except Exception as e:
            session.rollback()
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}", exc_info=True)
            raise

def print_statistics(session):
    """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    from sqlalchemy import func
    
    print("\n–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
    print("-" * 40)
    
    tables = [
        ("–¢–∏–ø—ã –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤", MaterialType),
        ("–¢–∏–ø—ã –ø—Ä–æ–¥—É–∫—Ü–∏–∏", ProductType),
        ("–¶–µ—Ö–∞", Workshop),
        ("–ü—Ä–æ–¥—É–∫—Ü–∏—è", Product)
    ]
    
    for name, model in tables:
        count = session.query(func.count(model.id)).scalar()
        print(f"{name}: {count}")
    
    # –°—á–∏—Ç–∞–µ–º —Å–≤—è–∑–∏
    link_count = session.query(func.count(product_workshop_table.c.id)).scalar()
    print(f"–°–≤—è–∑–∏ –ø—Ä–æ–¥—É–∫—Ü–∏–∏-—Ü–µ—Ö–æ–≤: {link_count}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    print("\nüîç –ü–†–û–í–ï–†–ö–ê –¢–ò–ü–û–í –î–ê–ù–ù–´–•:")
    print("-" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    negative_prices = session.query(Product).filter(Product.min_partner_price < 0).count()
    print(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–Ω: {negative_prices}")
    
    negative_time = session.query(product_workshop_table)\
        .filter(product_workshop_table.c.manufacturing_time_hours < 0)\
        .count()
    print(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏: {negative_time}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
    products_without_type = session.query(Product)\
        .filter(~Product.product_type_id.in_(session.query(ProductType.id)))\
        .count()
    print(f"–ü—Ä–æ–¥—É–∫—Ç–æ–≤ –±–µ–∑ —Ç–∏–ø–∞: {products_without_type}")
    
    products_without_material = session.query(Product)\
        .filter(~Product.material_id.in_(session.query(MaterialType.id)))\
        .count()
    print(f"–ü—Ä–æ–¥—É–∫—Ç–æ–≤ –±–µ–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–∞: {products_without_material}")

if __name__ == "__main__":
    main()